{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "46246386-fec1-4d42-bf10-698a4054dbda"
    }
   },
   "outputs": [],
   "source": [
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import iris\n",
    "import iris.pandas\n",
    "import iris.coord_categorisation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='iris')\n",
    "import dateutil.parser\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point, Polygon\n",
    "# Visualization\n",
    "import cartopy.util\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "# Plotting parameters\n",
    "plt.rcParams['mathtext.default'] = 'regular'\n",
    "def m2km(x, pos):\n",
    "    '''Convert meters to kilometers when plotting axis labels'''\n",
    "    return int(x*1e-3) #'{:1.1f}'.format(x*1e-3)\n",
    "savefig = True\n",
    "publish = True\n",
    "if publish:\n",
    "    mpl.rcParams['xtick.labelsize'] = 16\n",
    "    mpl.rcParams['ytick.labelsize'] = 20\n",
    "    mpl.rcParams['axes.titlesize'] = 22\n",
    "    mpl.rcParams['axes.labelsize'] = 20\n",
    "    plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varying range\n",
    "species_names_dict = {'ch4': {'latex': '$CH_4$', 'abbr': 'RH_C1', 'ppn': 'ppbvC', 'max': 2100},\n",
    "                      'c2h6': {'latex': '$C_2H_6$', 'abbr': 'RH_C2', 'ppn': 'pptvC', 'max': 6000}, \n",
    "                      'c3h8': {'latex': '$C_3H_8$', 'abbr': 'RH_C3', 'ppn': 'pptvC', 'max': 1000},\n",
    "                      'o3': {'latex': '$O_3$', 'abbr': 'O3', 'ppn': 'ppbv', 'max': 600},\n",
    "                      'oh': {'latex': 'OH', 'abbr': 'OH', 'ppn': 'pptv', 'max': 3.5},\n",
    "                      'no': {'latex': 'NO', 'abbr': 'NO', 'ppn': 'ppbv', 'max': 0.2}, # 0.5\n",
    "                      'meono2': {'latex': '$MeONO_2$', 'abbr': 'RONO2_C1', 'ppn': 'pptv', 'max': 70},\n",
    "                      'etono2': {'latex': '$EtONO_2$', 'abbr': 'RONO2_C2', 'ppn': 'pptv', 'max': 10},\n",
    "                      'nprono2': {'latex': '$nPrONO_2$', 'abbr': 'RONO2_C3n', 'ppn': 'pptv', 'max': 1},\n",
    "                      'iprono2': {'latex': '$iPrONO_2$', 'abbr': 'RONO2_C3i', 'ppn': 'pptv', 'max': 10}}\n",
    "# common range\n",
    "# species_names_dict = {'ch4': {'latex': '$CH_4$', 'abbr': 'RH_C1', 'ppn': 'ppbvC', 'max': 2100},\n",
    "#                       'c2h6': {'latex': '$C_2H_6$', 'abbr': 'RH_C2', 'ppn': 'pptvC', 'max': 8000}, \n",
    "#                       'c3h8': {'latex': '$C_3H_8$', 'abbr': 'RH_C3', 'ppn': 'pptvC', 'max': 8000},\n",
    "#                       'meono2': {'latex': '$MeONO_2$', 'abbr': 'RONO2_C1', 'ppn': 'pptv', 'max': 70},\n",
    "#                       'etono2': {'latex': '$EtONO_2$', 'abbr': 'RONO2_C2', 'ppn': 'pptv', 'max': 70},\n",
    "#                       'nprono2': {'latex': '$nPrONO_2$', 'abbr': 'RONO2_C3n', 'ppn': 'pptv', 'max': 20},\n",
    "#                       'iprono2': {'latex': '$iPrONO_2$', 'abbr': 'RONO2_C3i', 'ppn': 'pptv', 'max': 20}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_atom = Path('../../../../../../../obs/ATom/nc/data')\n",
    "# Select flights\n",
    "fname_atom_flight = 'MER-WAS_DC8_201702*.nc'\n",
    "# Read ATom data\n",
    "atom_dsinf = xr.open_mfdataset(sorted(path_to_atom.glob(fname_atom_flight)), decode_times=True)\n",
    "atom_dsmms = xr.open_mfdataset(sorted(path_to_atom.glob(fname_atom_flight)), group='MMS', decode_cf=True)\n",
    "atom_dswas = xr.open_mfdataset(sorted(path_to_atom.glob(fname_atom_flight)), group='WAS', decode_cf=True)\n",
    "atom_dsch4 = xr.open_mfdataset(sorted(path_to_atom.glob(fname_atom_flight)), group='NOAA-Picarro', decode_cf=True)\n",
    "atom_dsno = xr.open_mfdataset(sorted(path_to_atom.glob(fname_atom_flight)), group='NOyO3-NO', decode_cf=True)\n",
    "atom_dso3 = xr.open_mfdataset(sorted(path_to_atom.glob(fname_atom_flight)), group='NOyO3-O3', decode_cf=True)\n",
    "atom_dsoh = xr.open_mfdataset(sorted(path_to_atom.glob(fname_atom_flight)), group='ATHOS-HOx', decode_cf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "5bf220d9-75c8-489e-81fb-58c0a9a4f83d"
    }
   },
   "outputs": [],
   "source": [
    "# Choose UKCA run\n",
    "ukca_run_name = 'xojnh'\n",
    "compared_common_id = '170201_170221_1702_merge'\n",
    "path_to_ukca = Path('../../../../../processed') / ukca_run_name\n",
    "# Read UKCA data\n",
    "cb_nyrs_ch4 = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_rh.nc'), 'ch4')\n",
    "cb_nyrs_c2h6 = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_rh.nc'), 'c2h6')\n",
    "cb_nyrs_c3h8 = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_rh.nc'), 'c3h8')\n",
    "cb_nyrs_o3 = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_ox.nc'), 'o3')\n",
    "cb_nyrs_oh = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_ox.nc'), 'oh')\n",
    "cb_nyrs_no = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_nox.nc'), 'no')\n",
    "cb_nyrs_meono2 = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_rono2.nc'), 'meono2')\n",
    "cb_nyrs_etono2 = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_rono2.nc'), 'etono2')\n",
    "cb_nyrs_nprono2 = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_rono2.nc'), 'nprono2')\n",
    "if ukca_run_name == 'xojng' or ukca_run_name == 'xojnc':\n",
    "    cb_nyrs_iprono2 = cb_nyrs_nprono2 # no iPrONO2 variable in BASE or old BB run, while nPrONO2 was zero\n",
    "else:\n",
    "    cb_nyrs_iprono2 = iris.load_cube(str(path_to_ukca / f'{ukca_run_name}_relvl_rono2.nc'), 'iprono2')\n",
    "# Load UKCA geospatial coordinates\n",
    "ukca_lats = iris.load_cube(str(Path('../../../../../data') / 'um_orography_xnvtj.nc'), 'OROGRAPHY (/STRAT LOWER BC)').coord('latitude')\n",
    "ukca_lons = iris.load_cube(str(Path('../../../../../data') / 'um_orography_xnvtj.nc'), 'OROGRAPHY (/STRAT LOWER BC)').coord('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month and year coordinates\n",
    "iris.coord_categorisation.add_month(cb_nyrs_ch4, 'time', name='month')\n",
    "iris.coord_categorisation.add_month(cb_nyrs_c2h6, 'time', name='month')\n",
    "iris.coord_categorisation.add_month(cb_nyrs_c3h8, 'time', name='month')\n",
    "iris.coord_categorisation.add_month(cb_nyrs_o3, 'time', name='month')\n",
    "iris.coord_categorisation.add_month(cb_nyrs_oh, 'time', name='month')\n",
    "iris.coord_categorisation.add_month(cb_nyrs_no, 'time', name='month')\n",
    "iris.coord_categorisation.add_month(cb_nyrs_meono2, 'time', name='month')\n",
    "iris.coord_categorisation.add_month(cb_nyrs_etono2, 'time', name='month')\n",
    "iris.coord_categorisation.add_month(cb_nyrs_nprono2, 'time', name='month')\n",
    "if not ukca_run_name == 'xojng':\n",
    "    iris.coord_categorisation.add_month(cb_nyrs_iprono2, 'time', name='month')\n",
    "# Calculate monthly mean from 8 years of data\n",
    "cb_ch4 = cb_nyrs_ch4[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_c2h6 = cb_nyrs_c2h6[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_c3h8 = cb_nyrs_c3h8[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_o3 = cb_nyrs_o3[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_oh = cb_nyrs_oh[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_no = cb_nyrs_no[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_meono2 = cb_nyrs_meono2[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_etono2 = cb_nyrs_etono2[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_nprono2 = cb_nyrs_nprono2[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)\n",
    "cb_iprono2 = cb_nyrs_iprono2[24:120].extract(iris.Constraint(month='Feb')).aggregated_by(['month'], iris.analysis.MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to figures\n",
    "path_to_figs = Path('../../../../../../../results') / ukca_run_name / compared_common_id\n",
    "path_to_figs.mkdir(exist_ok=True) # create a new folder if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select geographical region/s for spacial averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datetimes from ATom data\n",
    "atom_datetime = atom_dsinf.time.values.astype('<M8[us]').astype(datetime)\n",
    "atom_date_strt = atom_datetime[0]\n",
    "atom_date_stop = atom_datetime[-1]\n",
    "# Extract spatial coordinates from ATom data\n",
    "sample_lats = np.asarray(atom_dsmms.G_LAT.data) \n",
    "sample_lons = np.asarray(atom_dsmms.G_LONG.data)\n",
    "sample_alts = np.asarray(atom_dsmms.G_ALT.data)\n",
    "# Create UKCA lat lon grid\n",
    "grid_lons, grid_lats = np.meshgrid(ukca_lons.points, ukca_lats.points)\n",
    "# Construct pairs of coordinate points\n",
    "sample_lon_lat_points = []\n",
    "for i, j in zip(sample_lons, sample_lats):\n",
    "    sample_lon_lat_points.append(Point(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a geographical region\n",
    "r1_llon_ukca, r1_ulon_ukca = 195.9375, 214.6875\n",
    "r1_llon, r1_ulon = r1_llon_ukca-360, r1_ulon_ukca-360\n",
    "r1_llat, r1_ulat = 21.875, 53.125\n",
    "r1 = Polygon([(r1_llon, r1_llat), (r1_llon, r1_ulat), (r1_ulon, r1_ulat), (r1_ulon, r1_llat)])\n",
    "r2_llon_ukca, r2_ulon_ukca = 169.6875, 201.5625\n",
    "r2_1_llon, r2_1_ulon = r2_llon_ukca, 180\n",
    "r2_2_llon, r2_2_ulon = -180, r2_ulon_ukca-360\n",
    "r2_llat, r2_ulat = -40.625, 20.625\n",
    "r2_1 = Polygon([(r2_1_llon, r2_llat), (r2_1_llon, r2_ulat), (r2_1_ulon, r2_ulat), (r2_1_ulon, r2_llat)])\n",
    "r2_2 = Polygon([(r2_2_llon, r2_llat), (r2_2_llon, r2_ulat), (r2_2_ulon, r2_ulat), (r2_2_ulon, r2_llat)])\n",
    "r3_llon_ukca, r3_ulon_ukca = 180.9375, 285.9375\n",
    "r3_llon, r3_ulon = r3_llon_ukca-360, r3_ulon_ukca-360\n",
    "r3_llat, r3_ulat = -70.625, -50.625\n",
    "r3 = Polygon([(r3_llon, r3_llat), (r3_llon, r3_ulat), (r3_ulon, r3_ulat), (r3_ulon, r3_llat)])\n",
    "r4_llon_ukca, r4_ulon_ukca = 312.1875, 334.6875\n",
    "r4_llon, r4_ulon = r4_llon_ukca-360, r4_ulon_ukca-360\n",
    "r4_llat, r4_ulat = -45.625, -25.625\n",
    "r4 = Polygon([(r4_llon, r4_llat), (r4_llon, r4_ulat), (r4_ulon, r4_ulat), (r4_ulon, r4_llat)])\n",
    "r5_llon_ukca, r5_ulon_ukca = 323.4375, 344.0625\n",
    "r5_llon, r5_ulon = r5_llon_ukca-360, r5_ulon_ukca-360\n",
    "r5_llat, r5_ulat = -6.875, 36.875\n",
    "r5 = Polygon([(r5_llon, r5_llat), (r5_llon, r5_ulat), (r5_ulon, r5_ulat), (r5_ulon, r5_llat)])\n",
    "r6_llon_ukca, r6_ulon_ukca = 321.5625, 338.4375\n",
    "r6_llon, r6_ulon = r6_llon_ukca-360, r6_ulon_ukca-360\n",
    "r6_llat, r6_ulat = 38.125, 63.125\n",
    "r6 = Polygon([(r6_llon, r6_llat), (r6_llon, r6_ulat), (r6_ulon, r6_ulat), (r6_ulon, r6_llat)])\n",
    "r7_llon_ukca, r7_ulon_ukca = 269.0625, 321.5625\n",
    "r7_llon, r7_ulon = r7_llon_ukca-360, r7_ulon_ukca-360\n",
    "r7_llat, r7_ulat = 59.375, 81.875\n",
    "r7 = Polygon([(r7_llon, r7_llat), (r7_llon, r7_ulat), (r7_ulon, r7_ulat), (r7_ulon, r7_llat)])\n",
    "# r8_llon_ukca, r8_ulon_ukca = 237.1875, 269.0625\n",
    "# r8_llon, r8_ulon = r8_llon_ukca-360, r8_ulon_ukca-360\n",
    "# r8_llat, r8_ulat = 31.875, 50.625\n",
    "# r8 = Polygon([(r8_llon, r8_llat), (r8_llon, r8_ulat), (r8_ulon, r8_ulat), (r8_ulon, r8_llat)])\n",
    "r9_llon_ukca, r9_ulon_ukca = 201.5625, 233.4375 # between 234 and 237.1875 there is a spike in alkanes!\n",
    "r9_llon, r9_ulon = r9_llon_ukca-360, r9_ulon_ukca-360\n",
    "r9_llat, r9_ulat = 61.875, 81.875\n",
    "r9 = Polygon([(r9_llon, r9_llat), (r9_llon, r9_ulat), (r9_ulon, r9_ulat), (r9_ulon, r9_llat)])\n",
    "# Find points within a region\n",
    "r1_points_within = []\n",
    "r2_1_points_within, r2_2_points_within= [], []\n",
    "r3_points_within = []\n",
    "r4_points_within = []\n",
    "r5_points_within = []\n",
    "r6_points_within = []\n",
    "r7_points_within = []\n",
    "# r8_points_within = []\n",
    "r9_points_within = []\n",
    "for p in sample_lon_lat_points:\n",
    "    r1_points_within.append(p.within(r1))\n",
    "    r2_1_points_within.append(p.within(r2_1))\n",
    "    r2_2_points_within.append(p.within(r2_2))\n",
    "    r3_points_within.append(p.within(r3))\n",
    "    r4_points_within.append(p.within(r4))\n",
    "    r5_points_within.append(p.within(r5))\n",
    "    r6_points_within.append(p.within(r6))\n",
    "    r7_points_within.append(p.within(r7))\n",
    "#     r8_points_within.append(p.within(r8))\n",
    "    r9_points_within.append(p.within(r9))\n",
    "r2_points_within = list(np.asarray(r2_1_points_within) | np.asarray(r2_2_points_within))\n",
    "# Combine points within and region corners into lists\n",
    "points_within_regions = [r1_points_within, r2_points_within, r3_points_within, r4_points_within, r5_points_within, \n",
    "                         r6_points_within, r7_points_within, r9_points_within]\n",
    "ukca_regions_corners = [[r1_llon_ukca, r1_ulon_ukca, r1_llat, r1_ulat], [r2_llon_ukca, r2_ulon_ukca, r2_llat, r2_ulat], \n",
    "                        [r3_llon_ukca, r3_ulon_ukca, r3_llat, r3_ulat], [r4_llon_ukca, r4_ulon_ukca, r4_llat, r4_ulat], \n",
    "                        [r5_llon_ukca, r5_ulon_ukca, r5_llat, r5_ulat], [r6_llon_ukca, r6_ulon_ukca, r6_llat, r6_ulat], \n",
    "                        [r7_llon_ukca, r7_ulon_ukca, r7_llat, r7_ulat], [r9_llon_ukca, r9_ulon_ukca, r9_llat, r9_ulat]]\n",
    "region_names = ['N Pacific', 'Central Pacific', 'S Pacific', 'SE Atlantic', 'Central Atlantic', 'N Atlantic', 'Greenland', 'W Canada']\n",
    "# points_within_regions = [r1_points_within, r2_points_within, r3_points_within, r4_points_within, r5_points_within, \n",
    "#                          r6_points_within, r7_points_within, r8_points_within, r9_points_within]\n",
    "# ukca_regions_corners = [[r1_llon_ukca, r1_ulon_ukca, r1_llat, r1_ulat], [r2_llon_ukca, r2_ulon_ukca, r2_llat, r2_ulat], \n",
    "#                         [r3_llon_ukca, r3_ulon_ukca, r3_llat, r3_ulat], [r4_llon_ukca, r4_ulon_ukca, r4_llat, r4_ulat], \n",
    "#                         [r5_llon_ukca, r5_ulon_ukca, r5_llat, r5_ulat], [r6_llon_ukca, r6_ulon_ukca, r6_llat, r6_ulat], \n",
    "#                         [r7_llon_ukca, r7_ulon_ukca, r7_llat, r7_ulat], [r8_llon_ukca, r8_ulon_ukca, r8_llat, r8_ulat], \n",
    "#                         [r9_llon_ukca, r9_ulon_ukca, r9_llat, r9_ulat]]\n",
    "# region_names = ['N Pacific', 'Central Pacific', 'S Pacific', 'SE Atlantic', 'Central Atlantic', 'N Atlantic', 'Greenland', 'Central and W USA', 'W Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region(lons, lats, points_within, ukca_llon, ukca_ulon, ukca_llat, ukca_ulat, llon, ulon, llat, ulat):\n",
    "    if (abs(llon) <= 180 <= abs(ulon)) or (abs(llon) >= 180 >= abs(ulon)):\n",
    "        projection = ccrs.PlateCarree(central_longitude=180)\n",
    "    else:\n",
    "        projection = ccrs.PlateCarree()\n",
    "    fig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(projection=projection), facecolor='w')\n",
    "    ax.scatter(lons, lats, transform=ccrs.PlateCarree())\n",
    "    ax.scatter(lons[points_within], lats[points_within], color='r', transform=ccrs.PlateCarree())\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[ukca_llon, ukca_llat], width=ukca_ulon-ukca_llon, height=ukca_ulat-ukca_llat, facecolor='b', alpha=0.2, transform=ccrs.PlateCarree()))\n",
    "#     ax.plot(grid_lons, grid_lats, color='b', alpha=0.7, transform=ccrs.PlateCarree())\n",
    "#     ax.plot(grid_lons.T, grid_lats.T, color='b', alpha=0.7, transform=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    ax.set_extent([llon, ulon, llat, ulat], crs=ccrs.PlateCarree())\n",
    "    ax.gridlines(draw_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r1_points_within, r1_llon_ukca, r1_ulon_ukca, r1_llat, r1_ulat, -170, -140, 15, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r2_points_within, r2_llon_ukca, r2_ulon_ukca, r2_llat, r2_ulat, -200, -120, -50, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r3_points_within, r3_llon_ukca, r3_ulon_ukca, r3_llat, r3_ulat, -190, -60, -90, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r4_points_within, r4_llon_ukca, r4_ulon_ukca, r4_llat, r4_ulat, -80, 20, -60, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r5_points_within, r5_llon_ukca, r5_ulon_ukca, r5_llat, r5_ulat, -80, 20, -60, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r6_points_within, r6_llon_ukca, r6_ulon_ukca, r6_llat, r6_ulat, -80, 20, 0, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r7_points_within, r7_llon_ukca, r7_ulon_ukca, r7_llat, r7_ulat, -100, 0, 0, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r8_points_within, r8_llon_ukca, r8_ulon_ukca, r8_llat, r8_ulat, -140, -80, 20, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_region(sample_lons, sample_lats, r9_points_within, r9_llon_ukca, r9_ulon_ukca, r9_llat, r9_ulat, -170, -80, 20, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regions(lons, lats, points_within_regions, ukca_regions_corners, llon, ulon, llat, ulat):\n",
    "    r1_points_within, r2_points_within, r3_points_within, r4_points_within, r5_points_within, r6_points_within, r7_points_within, r9_points_within = points_within_regions\n",
    "    [r1_llon, r1_ulon, r1_llat, r1_ulat] = ukca_regions_corners[0]\n",
    "    [r2_llon, r2_ulon, r2_llat, r2_ulat] = ukca_regions_corners[1]\n",
    "    [r3_llon, r3_ulon, r3_llat, r3_ulat] = ukca_regions_corners[2]\n",
    "    [r4_llon, r4_ulon, r4_llat, r4_ulat] = ukca_regions_corners[3]\n",
    "    [r5_llon, r5_ulon, r5_llat, r5_ulat] = ukca_regions_corners[4]\n",
    "    [r6_llon, r6_ulon, r6_llat, r6_ulat] = ukca_regions_corners[5]\n",
    "    [r7_llon, r7_ulon, r7_llat, r7_ulat] = ukca_regions_corners[6]\n",
    "#     [r8_llon, r8_ulon, r8_llat, r8_ulat] = ukca_regions_corners[7]\n",
    "    [r9_llon, r9_ulon, r9_llat, r9_ulat] = ukca_regions_corners[8]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,7), subplot_kw=dict(projection=ccrs.PlateCarree(central_longitude=180)), facecolor='w')\n",
    "    ax.scatter(lons, lats, color='grey', transform=ccrs.PlateCarree())\n",
    "    kwargs_sc = dict(color='k', transform=ccrs.PlateCarree())\n",
    "    ax.scatter(lons[r1_points_within], lats[r1_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r2_points_within], lats[r2_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r3_points_within], lats[r3_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r4_points_within], lats[r4_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r5_points_within], lats[r5_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r6_points_within], lats[r6_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r7_points_within], lats[r7_points_within], **kwargs_sc)\n",
    "#     ax.scatter(lons[r8_points_within], lats[r8_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r9_points_within], lats[r9_points_within], **kwargs_sc)\n",
    "    kwargs_patch = dict(facecolor='r', alpha=0.2, edgecolor='k', transform=ccrs.PlateCarree())\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r1_llon, r1_llat], width=r1_ulon-r1_llon, height=r1_ulat-r1_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r2_llon, r2_llat], width=r2_ulon-r2_llon, height=r2_ulat-r2_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r3_llon, r3_llat], width=r3_ulon-r3_llon, height=r3_ulat-r3_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r4_llon, r4_llat], width=r4_ulon-r4_llon, height=r4_ulat-r4_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r5_llon, r5_llat], width=r5_ulon-r5_llon, height=r5_ulat-r5_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r6_llon, r6_llat], width=r6_ulon-r6_llon, height=r6_ulat-r6_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r7_llon, r7_llat], width=r7_ulon-r7_llon, height=r7_ulat-r7_llat, **kwargs_patch))\n",
    "#     ax.add_patch(mpatches.Rectangle(xy=[r8_llon, r8_llat], width=r8_ulon-r8_llon, height=r8_ulat-r8_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r9_llon, r9_llat], width=r9_ulon-r9_llon, height=r9_ulat-r9_llat, **kwargs_patch))\n",
    "    ax.set_title('ATom', loc='right')\n",
    "    ax.set_title(f'{atom_date_strt.strftime(\"%b %Y\")}', loc='left')\n",
    "    ax.set_extent([llon, ulon, llat, ulat], crs=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    if publish:\n",
    "        fig.savefig(path_to_figs / 'publish' / f'{ukca_run_name}_{compared_common_id}_regions.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_regions(sample_lons, sample_lats, points_within_regions, ukca_regions_corners, -200, -5, -90, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process ATom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ATom C2H6, C2H4, C2H2, C3H8, C3H6 to pptvC to match UKCA lumped species, namely C2H6=C2H6+C2H4+C2H2, C3H8=C3H8+C3H6\n",
    "atom_dswas_c2h6 = atom_dswas['Ethane_WAS']*2 + atom_dswas['Ethene_WAS']*2 + atom_dswas['Ethyne_WAS']*2\n",
    "atom_dswas_c3h8 = atom_dswas['Propane_WAS']*3 + atom_dswas['Propene_WAS']*3\n",
    "# Convert xarray dataset with observational data to pandas dataframe\n",
    "atom_ch4 = atom_dsch4.CH4_NOAA.to_dataframe(name='ch4')\n",
    "atom_c2h6 = atom_dswas_c2h6.to_dataframe(name='c2h6')\n",
    "atom_c3h8 = atom_dswas_c3h8.to_dataframe(name='c3h8')\n",
    "atom_o3 = atom_dso3['O3_CL'].to_dataframe(name='o3')\n",
    "atom_oh = atom_dsoh['OH_pptv'].to_dataframe(name='oh')\n",
    "atom_no = atom_dsno['NO_CL'].to_dataframe(name='no')\n",
    "atom_meono2 = atom_dswas['MeONO2_WAS'].to_dataframe(name='meono2')\n",
    "atom_etono2 = atom_dswas['EtONO2_WAS'].to_dataframe(name='etono2')\n",
    "atom_nprono2 = atom_dswas['n-PrONO2_WAS'].to_dataframe(name='nprono2')\n",
    "atom_iprono2 = atom_dswas['i-PrONO2_WAS'].to_dataframe(name='iprono2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select longitudes and latitudes where ATom data is available\n",
    "lons_ch4_notnan = np.where(atom_ch4.ch4.isna()==False, sample_lons, atom_ch4.ch4)\n",
    "lats_ch4_notnan = np.where(atom_ch4.ch4.isna()==False, sample_lats, atom_ch4.ch4)\n",
    "lons_c2h6_notnan = np.where(atom_c2h6.c2h6.isna()==False, sample_lons, atom_c2h6.c2h6)\n",
    "lats_c2h6_notnan = np.where(atom_c2h6.c2h6.isna()==False, sample_lats, atom_c2h6.c2h6)\n",
    "lons_c3h8_notnan = np.where(atom_c3h8.c3h8.isna()==False, sample_lons, atom_c3h8.c3h8)\n",
    "lats_c3h8_notnan = np.where(atom_c3h8.c3h8.isna()==False, sample_lats, atom_c3h8.c3h8)\n",
    "lons_o3_notnan = np.where(atom_o3.o3.isna()==False, sample_lons, atom_o3.o3)\n",
    "lats_o3_notnan = np.where(atom_o3.o3.isna()==False, sample_lats, atom_o3.o3)\n",
    "lons_oh_notnan = np.where(atom_oh.oh.isna()==False, sample_lons, atom_oh.oh)\n",
    "lats_oh_notnan = np.where(atom_oh.oh.isna()==False, sample_lats, atom_oh.oh)\n",
    "lons_no_notnan = np.where(atom_no.no.isna()==False, sample_lons, atom_no.no)\n",
    "lats_no_notnan = np.where(atom_no.no.isna()==False, sample_lats, atom_no.no)\n",
    "lons_meono2_notnan = np.where(atom_meono2.meono2.isna()==False, sample_lons, atom_meono2.meono2)\n",
    "lats_meono2_notnan = np.where(atom_meono2.meono2.isna()==False, sample_lats, atom_meono2.meono2)\n",
    "lons_etono2_notnan = np.where(atom_etono2.etono2.isna()==False, sample_lons, atom_etono2.etono2)\n",
    "lats_etono2_notnan = np.where(atom_etono2.etono2.isna()==False, sample_lats, atom_etono2.etono2)\n",
    "lons_nprono2_notnan = np.where(atom_nprono2.nprono2.isna()==False, sample_lons, atom_nprono2.nprono2)\n",
    "lats_nprono2_notnan = np.where(atom_nprono2.nprono2.isna()==False, sample_lats, atom_nprono2.nprono2)\n",
    "lons_iprono2_notnan = np.where(atom_iprono2.iprono2.isna()==False, sample_lons, atom_iprono2.iprono2)\n",
    "lats_iprono2_notnan = np.where(atom_iprono2.iprono2.isna()==False, sample_lats, atom_iprono2.iprono2)\n",
    "lons_notnan = [lons_ch4_notnan, lons_c2h6_notnan, lons_c3h8_notnan, lons_o3_notnan, lons_oh_notnan, lons_no_notnan,\n",
    "               lons_meono2_notnan, lons_etono2_notnan, lons_nprono2_notnan, lons_iprono2_notnan]\n",
    "lats_notnan = [lats_ch4_notnan, lats_c2h6_notnan, lats_c3h8_notnan, lats_o3_notnan, lats_oh_notnan, lats_no_notnan,\n",
    "               lats_meono2_notnan, lats_etono2_notnan, lats_nprono2_notnan, lats_iprono2_notnan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regions_by_specie(lons, lats, points_within_regions, ukca_regions_corners, llon, ulon, llat, ulat, specie_name, abbr):\n",
    "    r1_points_within, r2_points_within, r3_points_within, r4_points_within, r5_points_within, r6_points_within, r7_points_within, r9_points_within = points_within_regions\n",
    "    [r1_llon, r1_ulon, r1_llat, r1_ulat] = ukca_regions_corners[0]\n",
    "    [r2_llon, r2_ulon, r2_llat, r2_ulat] = ukca_regions_corners[1]\n",
    "    [r3_llon, r3_ulon, r3_llat, r3_ulat] = ukca_regions_corners[2]\n",
    "    [r4_llon, r4_ulon, r4_llat, r4_ulat] = ukca_regions_corners[3]\n",
    "    [r5_llon, r5_ulon, r5_llat, r5_ulat] = ukca_regions_corners[4]\n",
    "    [r6_llon, r6_ulon, r6_llat, r6_ulat] = ukca_regions_corners[5]\n",
    "    [r7_llon, r7_ulon, r7_llat, r7_ulat] = ukca_regions_corners[6]\n",
    "#     [r8_llon, r8_ulon, r8_llat, r8_ulat] = ukca_regions_corners[7]\n",
    "    [r9_llon, r9_ulon, r9_llat, r9_ulat] = ukca_regions_corners[8]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,7), subplot_kw=dict(projection=ccrs.PlateCarree(central_longitude=180)), facecolor='w')\n",
    "    kwargs_sc = dict(color='k', transform=ccrs.PlateCarree())\n",
    "    ax.scatter(lons[r1_points_within], lats[r1_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r2_points_within], lats[r2_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r3_points_within], lats[r3_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r4_points_within], lats[r4_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r5_points_within], lats[r5_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r6_points_within], lats[r6_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r7_points_within], lats[r7_points_within], **kwargs_sc)\n",
    "#     ax.scatter(lons[r8_points_within], lats[r8_points_within], **kwargs_sc)\n",
    "    ax.scatter(lons[r9_points_within], lats[r9_points_within], **kwargs_sc)\n",
    "    kwargs_patch = dict(facecolor='red', alpha=0.2, edgecolor='k', transform=ccrs.PlateCarree())\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r1_llon, r1_llat], width=r1_ulon-r1_llon, height=r1_ulat-r1_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r2_llon, r2_llat], width=r2_ulon-r2_llon, height=r2_ulat-r2_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r3_llon, r3_llat], width=r3_ulon-r3_llon, height=r3_ulat-r3_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r4_llon, r4_llat], width=r4_ulon-r4_llon, height=r4_ulat-r4_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r5_llon, r5_llat], width=r5_ulon-r5_llon, height=r5_ulat-r5_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r6_llon, r6_llat], width=r6_ulon-r6_llon, height=r6_ulat-r6_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r7_llon, r7_llat], width=r7_ulon-r7_llon, height=r7_ulat-r7_llat, **kwargs_patch))\n",
    "#     ax.add_patch(mpatches.Rectangle(xy=[r8_llon, r8_llat], width=r8_ulon-r8_llon, height=r8_ulat-r8_llat, **kwargs_patch))\n",
    "    ax.add_patch(mpatches.Rectangle(xy=[r9_llon, r9_llat], width=r9_ulon-r9_llon, height=r9_ulat-r9_llat, **kwargs_patch))\n",
    "    ax.set_title('ATom', loc='center')\n",
    "    ax.set_title(f'{specie_name}', loc='right')\n",
    "    ax.set_title(f'{atom_date_strt.strftime(\"%b %Y\")}', loc='left')\n",
    "    ax.set_extent([llon, ulon, llat, ulat], crs=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    if publish:\n",
    "        fig.savefig(path_to_figs / 'publish' / f'{ukca_run_name}_{compared_common_id}_regions_{abbr}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (specie, specie_dict), lons, lats in zip(species_names_dict.items(), lons_notnan, lats_notnan):\n",
    "#     plot_regions_by_specie(lons, lats, points_within_regions, ukca_regions_corners, -200, -5, -90, 90, specie_dict['latex'], specie_dict['abbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_ts(atom, alts):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(atom, marker='o')\n",
    "#     ax2 = ax.twinx()\n",
    "#     ax2.plot(alts, marker='o', color='grey', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ts(atom_meono2[r1_points_within].values, atom_dsmms.G_ALT[r1_points_within].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ts(atom_meono2[r2_points_within].values, atom_dsmms.G_ALT[r2_points_within].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ts(atom_meono2[r3_points_within].values, atom_dsmms.G_ALT[r3_points_within].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose bins\n",
    "alt_bins = np.arange(0, 14000, 500)\n",
    "alt_bin_inds = np.arange(0, len(alt_bins)-1, 1)\n",
    "alt_bin_mids = np.arange(250, 13500, 500)\n",
    "alt_r1_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r1_points_within], alt_bins)\n",
    "alt_r2_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r2_points_within], alt_bins)\n",
    "alt_r3_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r3_points_within], alt_bins)\n",
    "alt_r4_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r4_points_within], alt_bins)\n",
    "alt_r5_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r5_points_within], alt_bins)\n",
    "alt_r6_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r6_points_within], alt_bins)\n",
    "alt_r7_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r7_points_within], alt_bins)\n",
    "# alt_r8_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r8_points_within], alt_bins)\n",
    "alt_r9_bin_inds = np.digitize(atom_dsmms.G_ALT.data[r9_points_within], alt_bins)\n",
    "alt_regions_bin_inds = [alt_r1_bin_inds, alt_r2_bin_inds, alt_r3_bin_inds,\n",
    "                        alt_r4_bin_inds, alt_r5_bin_inds, alt_r6_bin_inds,\n",
    "                        alt_r7_bin_inds, alt_r9_bin_inds]\n",
    "# alt_regions_bin_inds = [alt_r1_bin_inds, alt_r2_bin_inds, alt_r3_bin_inds,\n",
    "#                         alt_r4_bin_inds, alt_r5_bin_inds, alt_r6_bin_inds,\n",
    "#                         alt_r7_bin_inds, alt_r8_bin_inds, alt_r9_bin_inds]\n",
    "# Bin observational data\n",
    "atom2process = [atom_ch4, atom_c2h6, atom_c3h8, atom_o3, atom_oh, atom_no, atom_meono2, atom_etono2, atom_nprono2, atom_iprono2]\n",
    "atom_regional_vps = []\n",
    "for points_within_region, alt_region_bin_inds in zip(points_within_regions, alt_regions_bin_inds):\n",
    "    specie_dict = {}\n",
    "    for specie in atom2process:\n",
    "        stat_dict = {}\n",
    "        stat_dict['mean'] = specie[points_within_region].groupby(alt_region_bin_inds).mean().reindex(index=alt_bin_inds, fill_value=np.nan)\n",
    "        stat_dict['std'] = specie[points_within_region].groupby(alt_region_bin_inds).std().reindex(index=alt_bin_inds, fill_value=np.nan)\n",
    "        specie_dict[specie.columns[0]] = stat_dict\n",
    "    atom_regional_vps.append(specie_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process UKCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add coordinate bounds (for calculating area weights)\n",
    "ukca2process = iris.cube.CubeList([cb_ch4, cb_c2h6, cb_c3h8, cb_o3, cb_oh, cb_no, cb_meono2, cb_etono2, cb_nprono2, cb_iprono2])\n",
    "for cube in ukca2process:\n",
    "    for coord in ['longitude', 'latitude']:\n",
    "            if not cube.coord(coord).has_bounds():\n",
    "                cube.coord(coord).guess_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area weights for each region\n",
    "any_cube = cb_meono2\n",
    "regions = []\n",
    "for corners in ukca_regions_corners:\n",
    "    llon, ulon, llat, ulat = corners\n",
    "    lonlat_constraint = iris.Constraint(longitude=lambda cell: llon <= cell <= ulon, \n",
    "                                        latitude=lambda cell: llat <= cell <= ulat)\n",
    "    any_cube_extr = any_cube.extract(lonlat_constraint)\n",
    "    weights_cube = any_cube_extr.copy(data=iris.analysis.cartography.area_weights(any_cube_extr))\n",
    "    weights_cube.rename('area_weights')\n",
    "    regions.append(\n",
    "         {'corners': {k: v for k, v in zip(['llon', 'ulon', 'llat', 'ulat'], corners)},\n",
    "          'area_weights': weights_cube})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate regional mean vertical profiles and standart deviations\n",
    "stats = ('mean', 'std_dev')\n",
    "ukca_regional_vps = []\n",
    "for region in regions:\n",
    "    cube_dict = {}\n",
    "    corners = region['corners']\n",
    "    lonlat_constraint = iris.Constraint(longitude=lambda cell: corners['llon'] <= cell <= corners['ulon'], \n",
    "                                        latitude=lambda cell: corners['llat'] <= cell <= corners['ulat'])    \n",
    "    for cube in ukca2process.extract(lonlat_constraint):\n",
    "        stat_dict = {}\n",
    "        for stat in stats:\n",
    "            cubelist = iris.cube.CubeList()\n",
    "            for lbound, ubound in zip(alt_bins[:-1], alt_bins[1:]):\n",
    "                alt_constraint = iris.Constraint(altitude=lambda cell: lbound < cell <= ubound)              \n",
    "                cube_extr = cube.extract(alt_constraint)\n",
    "                if stat == 'mean':\n",
    "                    kwargs = {'weights': region['area_weights'].extract(alt_constraint).data}\n",
    "                else:\n",
    "                    kwargs = {}\n",
    "                cubelist.append(cube_extr.collapsed(['longitude', 'latitude', 'altitude'], getattr(iris.analysis, stat.upper()), **kwargs))\n",
    "            stat_dict[stat] = cubelist.merge_cube()\n",
    "        cube_dict[cube.name()] = stat_dict\n",
    "    ukca_regional_vps.append(cube_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ukca_regional_vps_xojnh' (list)\n"
     ]
    }
   ],
   "source": [
    "# Store vertical profiles for plotting in another notebook\n",
    "ukca_regional_vps_xojnh = ukca_regional_vps\n",
    "%store ukca_regional_vps_xojnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (cell_name, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"cell_name\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "sp = 'meono2'\n",
    "for i, r in enumerate(region_names):\n",
    "    a.append(np.max((ukca_regional_vps[i][sp]['mean'].data + ukca_regional_vps[i][sp]['std_dev'].data)))\n",
    "    b.append(np.nanmax((atom_regional_vps[i][sp]['mean'].values + atom_regional_vps[i][sp]['std'].values)))\n",
    "print(np.max(a), np.nanmax(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot region average vertical profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vp(atom_mean, ukca_mean, atom_std, ukca_std, region_name, region_number, specie_name, specie_abbr, specie_ppn, specie_max):\n",
    "    '''Plot area averaged vertical profile.'''\n",
    "    fig, ax = plt.subplots(figsize=(7,7), facecolor='w')\n",
    "    ax.errorbar(atom_mean, alt_bin_mids, xerr=atom_std, color='k', fmt='--o', linewidth=1, elinewidth=0.8, capsize=2)\n",
    "    ax.errorbar(ukca_mean, alt_bin_mids, xerr=ukca_std, color='r', fmt='--o', linewidth=1, elinewidth=0.8, capsize=2)\n",
    "    # common\n",
    "    ax.set_title(f'{specie_name}', loc='right')\n",
    "    ax.set_title(f'{region_name}', loc='center')\n",
    "    ax.set_title(f'{atom_date_strt.strftime(\"%b\")}', loc='left')\n",
    "    ax.set_xlabel(f'{specie_ppn}')\n",
    "    ax.set_xlim(0, specie_max)\n",
    "    try:\n",
    "        ax.set_xlim(0, max(np.nanmax(atom_mean+atom_std), np.nanmax(ukca_mean+ukca_std)))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    ax.set_ylabel('Altitude, km')\n",
    "    ax.set_ylim(-200,13500)\n",
    "    ax.set_yticks(alt_bins)\n",
    "    ax.set_yticklabels(map(int,(alt_bins/1000)))\n",
    "    ax.legend(['ATom', f'UKCA'], frameon=False)\n",
    "    for ytcklbl in ax.yaxis.get_ticklabels()[1::2]:\n",
    "        ytcklbl.set_visible(False)\n",
    "    if publish:\n",
    "        fig.savefig(path_to_figs / 'publish' / f'{ukca_run_name}_{compared_common_id}_vp_r{region_number}_{specie_abbr}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for specie, specie_dict in species_names_dict.items():\n",
    "#     for n, region_name in enumerate(region_names):\n",
    "#         plot_vp(atom_regional_vps[n][specie]['mean'].values, \n",
    "#                 ukca_regional_vps[n][specie]['mean'].data, \n",
    "#                 atom_regional_vps[n][specie]['std'].values, \n",
    "#                 ukca_regional_vps[n][specie]['std_dev'].data, region_name, n+1, specie_dict['latex'], specie_dict['abbr'], specie_dict['ppn'], specie_dict['max'])"
   ]
  }
 ],
 "metadata": {
  "@deathbeds/jupyterlab-fonts": {
   "styles": {
    ":root": {
     "--jp-code-font-size": "12px"
    }
   }
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
